# ğŸ“Š Azure Data Factory Incremental Ingestion Pipeline
## ğŸš€ Overview

A production-ready data pipeline that demonstrates enterprise data engineering practices using Azure services. This solution dynamically ingests CSV files, transforms data with business logic, and maintains data integrity with comprehensive error handling.

## ğŸ—ï¸ Architecture
<p align="center">
  <img src="diagram.png" alt="Description" width="400" style="border-radius: 10px; border: 1px solid #ddd;">
</p>

### ğŸ“ Data Model
#### ğŸ—ƒï¸ Staging Layer (Raw Ingestion)

| Table | Purpose | Characteristics |
| :--- | :--- | :--- |
| **stg_customers** | Raw customer data | â€¢ Accepts duplicates<br>â€¢ No constraints<br>â€¢ Full history |
| **stg_products** | Raw product data | â€¢ Accepts duplicates<br>â€¢ No constraints<br>â€¢ Full history |
| **stg_orders** | Raw order transactions | â€¢ Accepts invalid FKs<br>â€¢ No constraints<br>â€¢ Full history |


### ğŸ¯ Final Layer (Curated Data)

| Table | Type | Key Constraints | Purpose |
| :--- | :--- | :--- | :--- |
| **`customers`** | Dimension | `customer_id` (PK) | Deduplicated customer master |
| **`products`** | Dimension | `product_id` (PK) | Deduplicated product catalog |
| **`orders`** | Fact | `order_id` (PK)<br>`customer_id` (FK)<br>`product_id` (FK) | Validated transactions |

### âš ï¸ Error Handling

| Table | Columns | Purpose |
| :--- | :--- | :--- |
| **`orders_error`** | â€¢ Invalid order data<br>â€¢ Error reason<br>â€¢ Source file<br>â€¢ Timestamp | Quarantined invalid records with full traceability |

## ğŸ”„ Incremental Loading Strategy

### ğŸ“‚ File-Level Processing

| Aspect | Detail |
| :--- | :--- |
| **File Pattern** | `customers_YYYY-MM-DD.csv` |
| **Processing** | Dynamic discovery via **Get Metadata** |
| **Advantage** | No hardcoded file lists |

---

### ğŸ“Š Record-Level Processing

To ensure data integrity, a `MERGE` strategy is used to prevent duplicates and maintain a clean final layer.

```sql
MERGE final_table AS target
USING staging_table AS source
ON target.business_key = source.business_key
WHEN NOT MATCHED THEN
    INSERT (...) 
    VALUES (...);
```

#### Key Features:

* **âœ… Idempotent:** Safe for multiple executions; won't create duplicate records if re-run.
* **âœ… Incremental:** Processes only new or changed data to save on compute costs.
* **âœ… Scalable:** Optimized to handle growing data volumes efficiently.

### âš™ï¸ Azure Data Factory Pipeline

#### ğŸ”§ Datasets
| Dataset | Type | Configuration | Purpose |
| :--- | :--- | :--- | :--- |
| **`InputFolderDataset`** | Azure Blob | Container path | File listing only |
| **`InputFileDataset`** | Azure Blob | Parameterized path | Read specific CSV |
| **`SqlStagingDataset`** | Azure SQL | Parameterized table | Write to staging |



